All the following answers are sorted in descending order according to the value for each key in the list. They all in the format of a pair of (key, value) stored in a tuple, which then are put in a list. 
- Collection Background Language Model
[('the', 0.047522493072509824), ('i', 0.032413668336667964), ('and', 0.03232410802406665), ('to', 0.025476326522570095), ('a', 0.024140086658558473), ('was', 0.015318395867328935), ('of', 0.014849099829298044), ('it', 0.01465206714157515), ('in', 0.011660752700691227), ('is', 0.011553280325569648), ('for', 0.010972929499913126), ('that', 0.010322721630427578), ('my', 0.009604447923365032), ('you', 0.009122613441569956), ('this', 0.008986481766415958), ('they', 0.008167900509239937), ('we', 0.007798912021322519), ('with', 0.0073511104583159435), ('on', 0.0070107812704309465), ('nt', 0.00692659457658571)]
- Topic Language Model
"chinese" Topic Model:
[('the', 0.04910976325572295), ('and', 0.0315006847974956), ('i', 0.03042457444727059), ('a', 0.022402660927411465), ('to', 0.02142437879084328), ('it', 0.018880845235765994), ('was', 0.014576403834865975), ('of', 0.0141850909802387), ('is', 0.013989434552925064), ('in', 0.013891606339268244), ('my', 0.010467618861279592), ('chinese', 0.010076306006652318), ('that', 0.009489336724711406), ('food', 0.00929368029739777), ('you', 0.00851105458814322), ('this', 0.008413226374486401), ('for', 0.008315398160829584), ('we', 0.007532772451575034), ('not', 0.007434944237918215), ('with', 0.007434944237918215)]
"mexican" Topic Model:
[('the', 0.04895795903701042), ('and', 0.033192597915918075), ('i', 0.030991735537190084), ('a', 0.023311174991016887), ('to', 0.021020481494789797), ('it', 0.01751706791232483), ('was', 0.01648401006108516), ('of', 0.014462809917355372), ('is', 0.013474667624865252), ('in', 0.012261947538627381), ('this', 0.010375494071146246), ('that', 0.010330578512396695), ('food', 0.010285662953647143), ('for', 0.009881422924901186), ('you', 0.009746676248652534), ('mexican', 0.008848365073661517), ('my', 0.008803449514911965), ('with', 0.008623787279913761), ('nt', 0.0069619116061803805), ('s', 0.006827164929931728)]
- Normalization of Topic Language Models
Normalized "chinese" Topic Model:
[('poorest', 54.61582860496967), ('refunding', 54.61582860496967), ('phonebook', 54.61582860496967), ('railing', 54.61582860496967), ('burps', 54.61582860496967), ('servicemarketingsocial', 54.61582860496967), ('herd', 54.61582860496967), ('clumpiness', 54.61582860496967), ('burpy', 54.61582860496967), ('typo', 54.61582860496967), ('akin', 54.61582860496967), ('aging', 54.61582860496967), ('significance', 54.61582860496967), ('chestnuts', 54.61582860496967), ('ove', 54.61582860496967), ('capitalism', 54.61582860496967), ('ekkk', 54.61582860496967), ('lemongras', 54.61582860496967), ('persist', 54.61582860496967), ('caterpillar', 54.61582860496967)] 
Normalized "mexican" Topic Model:
[('forgone', 25.075592885375496), ('mirage', 25.075592885375496), ('slowclapprogression', 25.075592885375496), ('greeeeeeat', 25.075592885375496), ('avalanches', 25.075592885375496), ('differentiates', 25.075592885375496), ('phoney', 25.075592885375496), ('scribbled', 25.075592885375496), ('parter', 25.075592885375496), ('schneikies', 25.075592885375496), ('complexities', 25.075592885375496), ('halfnhalf', 25.075592885375496), ('unmotivated', 25.075592885375496), ('cochinita', 25.075592885375496), ('burpy', 25.075592885375496), ('cranium', 25.075592885375496), ('asterisks', 25.075592885375496), ('filbertos', 25.075592885375496), ('schmear', 25.075592885375496), ('sped', 25.075592885375496)]
The ranking order of words changes a lot by the normalization. Comparing the normalized list with the one without normalization, this list contains many different words with more descriptive characteristics. That is, instead of having determiners or prepositions as top-ranked words, like "the", "a", "of", etc., we have many meaningful words like "poorest", "capitalism", "phony", "schmear", "greeeeeeat" etc. that help express human feelings and emotions when people face something, and particularly food here. The normalization helps make the Topic Language Models more meaningful and categorical. 
- Smoothing of Background Language Model
The smoothed Collection Background Language Model:
[('the', 0.045880650131510006), ('i', 0.03129436625320129), ('and', 0.031207903396779778), ('to', 0.02459695339479113), ('a', 0.023306927576982203), ('was', 0.014790336219463482), ('of', 0.014337270851814769), ('it', 0.014147052567687448), ('in', 0.011259193163209016), ('is', 0.011155437735503206), ('for', 0.01059515842589182), ('that', 0.00996743808827166), ('my', 0.00927400597977115), ('you', 0.008808835812223427), ('this', 0.008677412270462733), ('they', 0.007887141762770132), ('we', 0.0075309147943135105), ('with', 0.007098600512205962), ('on', 0.0067700416578042235), ('nt', 0.0066887665727680045)]
The top 20 words of this smoothed background language model are not very different from the top 20 words in the unsmoothed background language model. And in fact, the values are pretty close.

Smoothing Normalized "chinese" Topic Model:
[('chinese', 56.02842756197041), ('chopstick', 49.50084376834279), ('shabu', 47.14366073175504), ('brocoli', 45.257914302484835), ('dragonfly', 42.42929465857953), ('caterpillar', 37.71492858540403), ('nee', 37.71492858540403), ('yung', 37.71492858540403), ('jury', 37.71492858540403), ('potshabu', 37.71492858540403), ('eyeballs', 37.71492858540403), ('lotus', 37.71492858540403), ('quack', 37.71492858540403), ('joyful', 37.71492858540403), ('nebraska', 37.71492858540403), ('twitter', 37.71492858540403), ('dim', 36.36796685021103), ('wa', 33.943435726863626), ('hong', 33.943435726863626), ('kong', 33.943435726863626)]
Smoothing Normalized "mexican" Topic Model:
[('mexican', 25.842722726728294), ('senor', 21.644920050305426), ('serrano', 20.77912324829321), ('jagershots', 19.48042804527488), ('mascot', 19.48042804527488), ('machaca', 19.48042804527488), ('gill', 19.48042804527488), ('rito', 19.48042804527488), ('macayo', 19.48042804527488), ('chimi', 18.552788614547506), ('arriba', 18.552788614547506), ('salsas', 17.981933580253738), ('cochinita', 17.315936040244342), ('luby', 17.315936040244342), ('surprises', 17.315936040244342), ('tomatillo', 17.315936040244342), ('parilla', 17.315936040244342), ('jedis', 17.315936040244342), ('lighter', 17.315936040244342), ('passports', 17.315936040244342)]
Based on the results we get after smoothing, we find that the top 20 words are very different from those I have obtained from the normalized topic language model. I am so happy to see that there appear quite a lot of words that appear to be really related to the real topic.
According to the top 20 words for "mexican", I find that words like "serrano", "salsas", "mexican", "machaca", "arriba", "rito", "macayo", "chimi", and "cochinita" all seem to be pretty semantically related to the word "mexican". Some of these words are just types of traditional Mexican foods. 


